{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e619e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Thesis Loader - Notebook Friendly Script\n",
    "Load thesis.md and split by headers, plus load associated images\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "# Configuration\n",
    "THESIS_FOLDER = \"thesis\"\n",
    "THESIS_FILE = \"Thesis.md\"\n",
    "IMAGE_FILES = [\n",
    "    \"ConfusionMatrix.png\",\n",
    "    \"diagram_1.png\",\n",
    "    \"diagram_2.png\",\n",
    "    \"loss_accuracy_precision&recall.png\"\n",
    "]\n",
    "\n",
    "\n",
    "def load_thesis(thesis_path):\n",
    "    \"\"\"\n",
    "    Load thesis markdown file and return its content\n",
    "\n",
    "    Args:\n",
    "        thesis_path: Path to the thesis.md file\n",
    "\n",
    "    Returns:\n",
    "        str: Full content of the thesis\n",
    "    \"\"\"\n",
    "    with open(thesis_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "\n",
    "def split_by_headers(content):\n",
    "    \"\"\"\n",
    "    Split thesis content by main headers (single # only)\n",
    "    Sub-headers (##, ###, etc.) are kept as part of the section content\n",
    "\n",
    "    Args:\n",
    "        content: Full thesis content as string\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries with 'title' and 'content' for each main section\n",
    "    \"\"\"\n",
    "    # Split by lines\n",
    "    lines = content.split('\\n')\n",
    "\n",
    "    sections = []\n",
    "    current_section = None\n",
    "\n",
    "    for line in lines:\n",
    "        # Check if line is a MAIN header (single # only)\n",
    "        header_match = re.match(r'^#\\s+(.+)$', line)\n",
    "\n",
    "        if header_match:\n",
    "            # Save previous section if exists\n",
    "            if current_section is not None:\n",
    "                sections.append(current_section)\n",
    "\n",
    "            # Start new section\n",
    "            title = header_match.group(1).strip()\n",
    "            current_section = {\n",
    "                'title': title,\n",
    "                'header_line': line,\n",
    "                'content': []\n",
    "            }\n",
    "        else:\n",
    "            # Add line to current section (including sub-headers)\n",
    "            if current_section is not None:\n",
    "                current_section['content'].append(line)\n",
    "            else:\n",
    "                # Content before first header\n",
    "                if not sections:\n",
    "                    sections.append({\n",
    "                        'title': 'Preamble',\n",
    "                        'header_line': '',\n",
    "                        'content': [line]\n",
    "                    })\n",
    "                else:\n",
    "                    sections[0]['content'].append(line)\n",
    "\n",
    "    # Don't forget the last section\n",
    "    if current_section is not None:\n",
    "        sections.append(current_section)\n",
    "\n",
    "    # Join content lines back into strings\n",
    "    for section in sections:\n",
    "        section['content'] = '\\n'.join(section['content']).strip()\n",
    "\n",
    "    return sections\n",
    "\n",
    "\n",
    "def load_images(thesis_folder, image_files):\n",
    "    \"\"\"\n",
    "    Load all images from the thesis folder\n",
    "\n",
    "    Args:\n",
    "        thesis_folder: Path to thesis folder\n",
    "        image_files: List of image filenames\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary mapping image names to PIL Image objects\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(thesis_folder, img_file)\n",
    "        if os.path.exists(img_path):\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                # Store with a friendly name (without extension)\n",
    "                img_name = os.path.splitext(img_file)[0]\n",
    "                images[img_name] = img\n",
    "                print(f\"✓ Loaded: {img_file} ({img.size[0]}x{img.size[1]})\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error loading {img_file}: {e}\")\n",
    "        else:\n",
    "            print(f\"✗ Not found: {img_file}\")\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def display_section_summary(sections):\n",
    "    \"\"\"\n",
    "    Display a summary of all sections\n",
    "\n",
    "    Args:\n",
    "        sections: List of section dictionaries\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"THESIS SECTIONS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for i, section in enumerate(sections):\n",
    "        title = section['title']\n",
    "        content_preview = section['content'][:100].replace('\\n', ' ')\n",
    "\n",
    "        print(f\"\\n[{i}] # {title}\")\n",
    "        print(f\"    Content length: {len(section['content'])} chars\")\n",
    "        print(f\"    Preview: {content_preview}...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e68b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Thesis and Images...\n",
      "\n",
      "Loading thesis from: thesis\\Thesis.md\n",
      "✓ Loaded 128543 characters\n",
      "\n",
      "Splitting thesis by headers...\n",
      "✓ Found 17 sections\n",
      "\n",
      "Loading images...\n",
      "✓ Loaded: ConfusionMatrix.png (784x701)\n",
      "✓ Loaded: diagram_1.png (2936x3840)\n",
      "✓ Loaded: diagram_2.png (3840x2940)\n",
      "✓ Loaded: loss_accuracy_precision&recall.png (1490x490)\n",
      "\n",
      "✓ Loaded 4 images\n",
      "\n",
      "======================================================================\n",
      "THESIS SECTIONS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "[0] # Research Presentation & Literature Review\n",
      "    Content length: 14226 chars\n",
      "    Preview: ## Introduction: The Convergence of Artificial Intelligence and Medical Imaging  The integration of ...\n",
      "\n",
      "[1] # Critical Analysis & Theoretical Application\n",
      "    Content length: 15327 chars\n",
      "    Preview: ## Theoretical Foundation: Why Dual-Input Architecture Succeeds  The exceptional performance achieve...\n",
      "\n",
      "[2] # Methodology & Design Process\n",
      "    Content length: 17197 chars\n",
      "    Preview: ## Research Design Framework and Functional Requirements Integration  This research adopted a system...\n",
      "\n",
      "[3] # Product Development & Implementation\n",
      "    Content length: 3607 chars\n",
      "    Preview: ## System Architecture Implementation: Bringing Innovation to Life  The implementation transforms th...\n",
      "\n",
      "[4] # Initialize workflow\n",
      "    Content length: 108 chars\n",
      "    Preview: workflow = ShoulderImplantWorkflow(     data_dir=\"data\",     output_dir=\"outputs\",      model_dir=\"m...\n",
      "\n",
      "[5] # Run complete training pipeline\n",
      "    Content length: 100 chars\n",
      "    Preview: success = workflow.run_complete_workflow(     epochs=50,     batch_size=16,     use_detection=True )...\n",
      "\n",
      "[6] # Make predictions on new images\n",
      "    Content length: 211 chars\n",
      "    Preview: results = workflow.predict_single_image(     \"path/to/xray.jpg\",      \"models/final_model.h5\" ) ### ...\n",
      "\n",
      "[7] # Training process from main_workflow.py\n",
      "    Content length: 6604 chars\n",
      "    Preview: def train_model(self, epochs=50, batch_size=16):     # Initialize classifier     self.classifier = O...\n",
      "\n",
      "[8] # Effective sample size class weighting implementation\n",
      "    Content length: 348 chars\n",
      "    Preview: def compute_effective_class_weights(class_counts, beta=0.9999):     effective_nums = []     for coun...\n",
      "\n",
      "[9] # Advanced augmentation implementation\n",
      "    Content length: 2131 chars\n",
      "    Preview: class MixUpAugmentation:     def __init__(self, alpha=0.2):         self.alpha = alpha              ...\n",
      "\n",
      "[10] # Training configuration implementation\n",
      "    Content length: 2405 chars\n",
      "    Preview: class TrainingConfig:     def __init__(self):         self.batch_size = 16         self.learning_rat...\n",
      "\n",
      "[11] # Performance evaluation implementation\n",
      "    Content length: 2878 chars\n",
      "    Preview: def comprehensive_evaluation(model, test_data):     predictions = model.predict(test_data)          ...\n",
      "\n",
      "[12] # Comprehensive Evaluation & Results\n",
      "    Content length: 18609 chars\n",
      "    Preview: ## Executive Summary of Performance Achievements  The comprehensive evaluation of the advanced two-s...\n",
      "\n",
      "[13] # Project Summary & Impact\n",
      "    Content length: 5524 chars\n",
      "    Preview: ## Research Excellence and Technical Achievement  This project demonstrates strong technical compete...\n",
      "\n",
      "[14] # Project Management Documentation\n",
      "    Content length: 14138 chars\n",
      "    Preview: ## Executive Project Overview and Success Metrics  The successful delivery of this advanced deep lea...\n",
      "\n",
      "[15] # Executive Summary & Management Summary\n",
      "    Content length: 7196 chars\n",
      "    Preview: ## Transformative Healthcare Innovation: Breakthrough AI Performance Enabling Clinical Impact  This ...\n",
      "\n",
      "[16] # References\n",
      "    Content length: 16921 chars\n",
      "    Preview: **Aburass, S., Dorgham, O., Al Shaqsi, J., Rumman, M. A., & Al-Kadi, O. (2025). Vision transformers ...\n",
      "\n",
      "Saving sections to JSONL...\n",
      "✓ Saved 17 sections to thesis\\thesis_sections.jsonl\n",
      "\n",
      "======================================================================\n",
      "AVAILABLE VARIABLES:\n",
      "======================================================================\n",
      "- thesis_content : Full thesis text\n",
      "- sections       : List of section dicts (title, content)\n",
      "- images         : Dict of PIL Image objects\n",
      "  Image keys: ['ConfusionMatrix', 'diagram_1', 'diagram_2', 'loss_accuracy_precision&recall']\n",
      "\n",
      "Example usage:\n",
      "  sections[0]['title']  # Get first section title\n",
      "  sections[0]['content']  # Get content (includes sub-headers)\n",
      "  images['ConfusionMatrix'].show()  # Display confusion matrix\n",
      "\n",
      "JSONL file saved to: thesis/thesis_sections.jsonl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Thesis Loader - Notebook Friendly Script\n",
    "Load thesis.md and split by headers, plus load associated images\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "THESIS_FOLDER = \"thesis\"\n",
    "THESIS_FILE = \"Thesis.md\"\n",
    "IMAGE_FILES = [\n",
    "    \"ConfusionMatrix.png\",\n",
    "    \"diagram_1.png\",\n",
    "    \"diagram_2.png\",\n",
    "    \"loss_accuracy_precision&recall.png\"\n",
    "]\n",
    "\n",
    "\n",
    "def load_thesis(thesis_path):\n",
    "    \"\"\"\n",
    "    Load thesis markdown file and return its content\n",
    "\n",
    "    Args:\n",
    "        thesis_path: Path to the thesis.md file\n",
    "\n",
    "    Returns:\n",
    "        str: Full content of the thesis\n",
    "    \"\"\"\n",
    "    with open(thesis_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "\n",
    "def split_by_headers(content):\n",
    "    \"\"\"\n",
    "    Split thesis content by main headers (single # only)\n",
    "    Sub-headers (##, ###, etc.) are kept as part of the section content\n",
    "\n",
    "    Args:\n",
    "        content: Full thesis content as string\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries with 'title' and 'content' for each main section\n",
    "    \"\"\"\n",
    "    # Split by lines\n",
    "    lines = content.split('\\n')\n",
    "\n",
    "    sections = []\n",
    "    current_section = None\n",
    "\n",
    "    for line in lines:\n",
    "        # Check if line is a MAIN header (single # only)\n",
    "        header_match = re.match(r'^#\\s+(.+)$', line)\n",
    "\n",
    "        if header_match:\n",
    "            # Save previous section if exists\n",
    "            if current_section is not None:\n",
    "                sections.append(current_section)\n",
    "\n",
    "            # Start new section\n",
    "            title = header_match.group(1).strip()\n",
    "            current_section = {\n",
    "                'title': title,\n",
    "                'header_line': line,\n",
    "                'content': []\n",
    "            }\n",
    "        else:\n",
    "            # Add line to current section (including sub-headers)\n",
    "            if current_section is not None:\n",
    "                current_section['content'].append(line)\n",
    "            else:\n",
    "                # Content before first header\n",
    "                if not sections:\n",
    "                    sections.append({\n",
    "                        'title': 'Preamble',\n",
    "                        'header_line': '',\n",
    "                        'content': [line]\n",
    "                    })\n",
    "                else:\n",
    "                    sections[0]['content'].append(line)\n",
    "\n",
    "    # Don't forget the last section\n",
    "    if current_section is not None:\n",
    "        sections.append(current_section)\n",
    "\n",
    "    # Join content lines back into strings\n",
    "    for section in sections:\n",
    "        section['content'] = '\\n'.join(section['content']).strip()\n",
    "\n",
    "    return sections\n",
    "\n",
    "\n",
    "def load_images(thesis_folder, image_files):\n",
    "    \"\"\"\n",
    "    Load all images from the thesis folder\n",
    "\n",
    "    Args:\n",
    "        thesis_folder: Path to thesis folder\n",
    "        image_files: List of image filenames\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary mapping image names to PIL Image objects\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(thesis_folder, img_file)\n",
    "        if os.path.exists(img_path):\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                # Store with a friendly name (without extension)\n",
    "                img_name = os.path.splitext(img_file)[0]\n",
    "                images[img_name] = img\n",
    "                print(f\"✓ Loaded: {img_file} ({img.size[0]}x{img.size[1]})\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error loading {img_file}: {e}\")\n",
    "        else:\n",
    "            print(f\"✗ Not found: {img_file}\")\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def save_sections_to_jsonl(sections, output_path):\n",
    "    \"\"\"\n",
    "    Save sections to JSONL format with metadata\n",
    "\n",
    "    Args:\n",
    "        sections: List of section dictionaries\n",
    "        output_path: Path to output JSONL file\n",
    "\n",
    "    Each line in the JSONL file contains:\n",
    "    {\n",
    "        \"section_number\": <int>,\n",
    "        \"header\": <string>,\n",
    "        \"content\": <string>\n",
    "    }\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for i, section in enumerate(sections):\n",
    "            jsonl_entry = {\n",
    "                \"section_number\": i,\n",
    "                \"header\": section['title'],\n",
    "                \"content\": section['content']\n",
    "            }\n",
    "            f.write(json.dumps(jsonl_entry, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    print(f\"✓ Saved {len(sections)} sections to {output_path}\")\n",
    "\n",
    "\n",
    "def display_section_summary(sections):\n",
    "    \"\"\"\n",
    "    Display a summary of all sections\n",
    "\n",
    "    Args:\n",
    "        sections: List of section dictionaries\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"THESIS SECTIONS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for i, section in enumerate(sections):\n",
    "        title = section['title']\n",
    "        content_preview = section['content'][:100].replace('\\n', ' ')\n",
    "\n",
    "        print(f\"\\n[{i}] # {title}\")\n",
    "        print(f\"    Content length: {len(section['content'])} chars\")\n",
    "        print(f\"    Preview: {content_preview}...\")\n",
    "\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading Thesis and Images...\\n\")\n",
    "\n",
    "    # Build paths\n",
    "    thesis_path = os.path.join(THESIS_FOLDER, THESIS_FILE)\n",
    "\n",
    "    # 1. Load thesis content\n",
    "    print(f\"Loading thesis from: {thesis_path}\")\n",
    "    thesis_content = load_thesis(thesis_path)\n",
    "    print(f\"✓ Loaded {len(thesis_content)} characters\\n\")\n",
    "\n",
    "    # 2. Split by headers\n",
    "    print(\"Splitting thesis by headers...\")\n",
    "    sections = split_by_headers(thesis_content)\n",
    "    print(f\"✓ Found {len(sections)} sections\\n\")\n",
    "\n",
    "    # 3. Load images\n",
    "    print(\"Loading images...\")\n",
    "    images = load_images(THESIS_FOLDER, IMAGE_FILES)\n",
    "    print(f\"\\n✓ Loaded {len(images)} images\")\n",
    "\n",
    "    # 4. Display summary\n",
    "    display_section_summary(sections)\n",
    "\n",
    "    # 5. Save to JSONL\n",
    "    print(\"\\nSaving sections to JSONL...\")\n",
    "    jsonl_output_path = os.path.join(THESIS_FOLDER, \"thesis_sections.jsonl\")\n",
    "    save_sections_to_jsonl(sections, jsonl_output_path)\n",
    "\n",
    "    # Return key variables for notebook use\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"AVAILABLE VARIABLES:\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"- thesis_content : Full thesis text\")\n",
    "    print(\"- sections       : List of section dicts (title, content)\")\n",
    "    print(\"- images         : Dict of PIL Image objects\")\n",
    "    print(f\"  Image keys: {list(images.keys())}\")\n",
    "    print(\"\\nExample usage:\")\n",
    "    print(\"  sections[0]['title']  # Get first section title\")\n",
    "    print(\"  sections[0]['content']  # Get content (includes sub-headers)\")\n",
    "    print(\"  images['ConfusionMatrix'].show()  # Display confusion matrix\")\n",
    "    print(\"\\nJSONL file saved to: thesis/thesis_sections.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b0baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
